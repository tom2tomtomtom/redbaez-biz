{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECD-Eye POC: Fine-Tuning Preparation\n",
    "\n",
    "This notebook converts ECD rankings into the JSONL format required for OpenAI fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "\n",
    "First, let's load the ECD rankings and baseline taglines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Paths\n",
    "DATA_DIR = Path(\"../data\")\n",
    "RANKINGS_FILE = DATA_DIR / \"rankings.csv\"\n",
    "BASELINE_FILE = DATA_DIR / \"baseline.csv\"\n",
    "\n",
    "# Load rankings\n",
    "rankings_df = pd.read_csv(RANKINGS_FILE)\n",
    "print(f\"Loaded {len(rankings_df)} rankings\")\n",
    "\n",
    "# Load baseline taglines\n",
    "baseline_df = pd.read_csv(BASELINE_FILE)\n",
    "print(f\"Loaded {len(baseline_df)} baseline taglines\")\n",
    "\n",
    "# Display first few rows of each\n",
    "print(\"\\nRankings:\")\n",
    "rankings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"\\nBaseline Taglines:\")\n",
    "baseline_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analyze Rankings\n",
    "\n",
    "Let's analyze the ECD rankings to understand their preferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Count how many times each position (1-5) appears in each rank column\n",
    "rank_counts = pd.DataFrame({\n",
    "    \"Rank 1\": rankings_df[\"rank_1\"].value_counts().sort_index(),\n",
    "    \"Rank 2\": rankings_df[\"rank_2\"].value_counts().sort_index(),\n",
    "    \"Rank 3\": rankings_df[\"rank_3\"].value_counts().sort_index(),\n",
    "    \"Rank 4\": rankings_df[\"rank_4\"].value_counts().sort_index(),\n",
    "    \"Rank 5\": rankings_df[\"rank_5\"].value_counts().sort_index()\n",
    "})\n",
    "\n",
    "rank_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize the distribution of rankings\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(rank_counts, annot=True, cmap=\"YlGnBu\", fmt=\"d\")\n",
    "plt.title(\"Distribution of Rankings\")\n",
    "plt.xlabel(\"Tagline Position\")\n",
    "plt.ylabel(\"Rank (1 = Best, 5 = Worst)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare Fine-Tuning Data\n",
    "\n",
    "Now, let's prepare the fine-tuning data in the format required by OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Prepare fine-tuning data\n",
    "finetune_data = []\n",
    "\n",
    "for _, row in rankings_df.iterrows():\n",
    "    brief_id = row[\"brief_id\"]\n",
    "    brief = row[\"brief\"]\n",
    "    \n",
    "    # Get the taglines in order of ranking\n",
    "    baseline_row = baseline_df[baseline_df[\"brief_id\"] == brief_id].iloc[0]\n",
    "    taglines = [\n",
    "        baseline_row[\"tagline_1\"],\n",
    "        baseline_row[\"tagline_2\"],\n",
    "        baseline_row[\"tagline_3\"],\n",
    "        baseline_row[\"tagline_4\"],\n",
    "        baseline_row[\"tagline_5\"]\n",
    "    ]\n",
    "    \n",
    "    # Get the rankings (1 to 5, where 1 is best)\n",
    "    rankings = [\n",
    "        row[\"rank_1\"],\n",
    "        row[\"rank_2\"],\n",
    "        row[\"rank_3\"],\n",
    "        row[\"rank_4\"],\n",
    "        row[\"rank_5\"]\n",
    "    ]\n",
    "    \n",
    "    # Create a mapping of tagline index to rank\n",
    "    tagline_ranks = {i: rank for i, rank in enumerate(rankings)}\n",
    "    \n",
    "    # Sort taglines by rank\n",
    "    sorted_taglines = [taglines[i] for i in sorted(tagline_ranks, key=tagline_ranks.get)]\n",
    "    \n",
    "    # Get the top-ranked tagline\n",
    "    best_tagline = sorted_taglines[0]\n",
    "    \n",
    "    # Create fine-tuning example\n",
    "    finetune_example = {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a punchy award-winning copywriter.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Write a punchy tagline (â‰¤7 words) for: {brief}\"\n",
    "            }\n",
    "        ],\n",
    "        \"response\": best_tagline\n",
    "    }\n",
    "    \n",
    "    finetune_data.append(finetune_example)\n",
    "\n",
    "# Display the first few examples\n",
    "finetune_data[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save Fine-Tuning Data\n",
    "\n",
    "Finally, let's save the fine-tuning data to a JSONL file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save fine-tuning data to JSONL file\n",
    "finetune_file = DATA_DIR / \"fine_tune.jsonl\"\n",
    "with open(finetune_file, \"w\") as f:\n",
    "    for example in finetune_data:\n",
    "        f.write(json.dumps(example) + \"\\n\")\n",
    "\n",
    "print(f\"Fine-tuning data saved to {finetune_file}\")\n",
    "print(f\"Number of examples: {len(finetune_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Verify Fine-Tuning Data\n",
    "\n",
    "Let's verify that the fine-tuning data is in the correct format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Read the JSONL file back in\n",
    "with open(finetune_file, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Parse each line as JSON\n",
    "examples = [json.loads(line) for line in lines]\n",
    "\n",
    "# Display the first example\n",
    "examples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check that all examples have the required fields\n",
    "for i, example in enumerate(examples):\n",
    "    if \"messages\" not in example or \"response\" not in example:\n",
    "        print(f\"Example {i} is missing required fields\")\n",
    "    if len(example[\"messages\"]) != 2:\n",
    "        print(f\"Example {i} has {len(example['messages'])} messages instead of 2\")\n",
    "    if example[\"messages\"][0][\"role\"] != \"system\" or example[\"messages\"][1][\"role\"] != \"user\":\n",
    "        print(f\"Example {i} has incorrect message roles\")\n",
    "\n",
    "print(f\"All {len(examples)} examples are in the correct format\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Next Steps\n",
    "\n",
    "Now that we have prepared the fine-tuning data, we can submit a fine-tuning job to OpenAI using the `submit_finetune.py` script.\n",
    "\n",
    "```bash\n",
    "python ../scripts/submit_finetune.py\n",
    "```\n",
    "\n",
    "This will submit a fine-tuning job to OpenAI and save the model ID to `data/model_id.txt`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
